"""
===========================================
æ¸…ç†å’Œç»´æŠ¤ä»»åŠ¡ (Cleanup Tasks)
===========================================

ä½œç”¨ï¼š
  å®šæœŸæ¸…ç†å’Œç»´æŠ¤ç³»ç»Ÿæ•°æ®

ä¸ºä»€ä¹ˆéœ€è¦æ¸…ç†ä»»åŠ¡ï¼Ÿ
  - åˆ é™¤è¿‡æœŸæ•°æ®ï¼ˆèŠ‚çœç©ºé—´ï¼‰
  - æ¸…ç†ç¼“å­˜
  - æ•°æ®åº“ä¼˜åŒ–
  - å¥åº·æ£€æŸ¥

ä½¿ç”¨åœºæ™¯ï¼š
  - æ¯å¤©æ¸…ç†è¿‡æœŸ Token
  - æ¯å‘¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
  - æ¯æœˆå½’æ¡£æ—§æ•°æ®
"""

import time
import random
from celery import shared_task
from datetime import datetime, timedelta


# ============================================================
# æ•°æ®æ¸…ç†ä»»åŠ¡
# ============================================================

@shared_task(name="tasks.cleanup_tasks.cleanup_expired_data")
def cleanup_expired_data():
    """
    æ¸…ç†è¿‡æœŸæ•°æ®

    å®šæ—¶ä»»åŠ¡:
        æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œ

    æ¸…ç†å†…å®¹:
        - è¿‡æœŸçš„ Token
        - è¿‡æœŸçš„ Session
        - ä¸´æ—¶æ–‡ä»¶
        - å·²åˆ é™¤ç”¨æˆ·çš„æ•°æ®
    """
    print(f"ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®...")

    # 1. æ¸…ç†è¿‡æœŸ Token
    print("   æ¸…ç†è¿‡æœŸ Token...")
    # å®é™…ä»£ç :
    # from datetime import datetime, timedelta
    # from models.token import Token
    # expired_date = datetime.now() - timedelta(days=7)
    # await db.execute(
    #     delete(Token).where(Token.created_at < expired_date)
    # )

    time.sleep(1)
    deleted_tokens = random.randint(10, 100)
    print(f"   âœ… åˆ é™¤ {deleted_tokens} ä¸ªè¿‡æœŸ Token")

    # 2. æ¸…ç†è¿‡æœŸ Session
    print("   æ¸…ç†è¿‡æœŸ Session...")
    time.sleep(1)
    deleted_sessions = random.randint(50, 200)
    print(f"   âœ… åˆ é™¤ {deleted_sessions} ä¸ªè¿‡æœŸ Session")

    # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    print("   æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    # import os
    # import glob
    # temp_files = glob.glob('/tmp/*.tmp')
    # for file in temp_files:
    #     os.remove(file)

    time.sleep(1)
    deleted_files = random.randint(5, 30)
    print(f"   âœ… åˆ é™¤ {deleted_files} ä¸ªä¸´æ—¶æ–‡ä»¶")

    # 4. æ¸…ç† Redis è¿‡æœŸç¼“å­˜
    print("   æ¸…ç† Redis è¿‡æœŸç¼“å­˜...")
    # from core.redis import redis_cache
    # await redis_cache.delete_pattern("temp:*")

    time.sleep(1)

    print(f"âœ… æ¸…ç†å®Œæˆ!")

    return {
        "deleted_tokens": deleted_tokens,
        "deleted_sessions": deleted_sessions,
        "deleted_files": deleted_files
    }


@shared_task(name="tasks.cleanup_tasks.cleanup_old_logs")
def cleanup_old_logs(days_to_keep: int = 30):
    """
    æ¸…ç†æ—§æ—¥å¿—

    å‚æ•°:
        days_to_keep: ä¿ç•™å¤©æ•°ï¼ˆé»˜è®¤ 30 å¤©ï¼‰

    å®šæ—¶ä»»åŠ¡:
        æ¯å‘¨æ—¥å‡Œæ™¨æ‰§è¡Œ

    è°ƒç”¨æ–¹å¼:
        cleanup_old_logs.delay(days_to_keep=30)
    """
    print(f"ğŸ§¹ æ¸…ç† {days_to_keep} å¤©å‰çš„æ—¥å¿—...")

    cutoff_date = datetime.now() - timedelta(days=days_to_keep)

    print(f"   åˆ é™¤ {cutoff_date.strftime('%Y-%m-%d')} ä¹‹å‰çš„æ—¥å¿—...")

    # å®é™…ä»£ç :
    # import glob
    # import os
    # from datetime import datetime
    #
    # log_files = glob.glob('logs/*.log')
    # for log_file in log_files:
    #     file_time = datetime.fromtimestamp(os.path.getmtime(log_file))
    #     if file_time < cutoff_date:
    #         os.remove(log_file)

    time.sleep(2)

    deleted_logs = random.randint(10, 50)

    print(f"âœ… åˆ é™¤ {deleted_logs} ä¸ªæ—¥å¿—æ–‡ä»¶")

    return {"deleted_logs": deleted_logs}


@shared_task(name="tasks.cleanup_tasks.archive_old_data")
def archive_old_data(table_name: str, months_to_keep: int = 6):
    """
    å½’æ¡£æ—§æ•°æ®

    å‚æ•°:
        table_name: è¡¨å
        months_to_keep: ä¿ç•™æœˆæ•°

    ç”¨é€”:
        - å°†æ—§æ•°æ®ç§»åˆ°å½’æ¡£è¡¨
        - ä¿æŒä¸»è¡¨æ•°æ®é‡å°
        - æé«˜æŸ¥è¯¢æ€§èƒ½

    è°ƒç”¨æ–¹å¼:
        archive_old_data.delay(table_name="orders", months_to_keep=6)
    """
    print(f"ğŸ§¹ å½’æ¡£ {table_name} è¡¨çš„æ—§æ•°æ®...")
    print(f"   ä¿ç•™æœ€è¿‘ {months_to_keep} ä¸ªæœˆçš„æ•°æ®")

    cutoff_date = datetime.now() - timedelta(days=months_to_keep * 30)

    # å®é™…ä»£ç :
    # 1. å°†æ—§æ•°æ®å¤åˆ¶åˆ°å½’æ¡£è¡¨
    # await db.execute(
    #     f"INSERT INTO {table_name}_archive SELECT * FROM {table_name} WHERE created_at < :cutoff",
    #     {"cutoff": cutoff_date}
    # )
    #
    # 2. åˆ é™¤ä¸»è¡¨ä¸­çš„æ—§æ•°æ®
    # await db.execute(
    #     f"DELETE FROM {table_name} WHERE created_at < :cutoff",
    #     {"cutoff": cutoff_date}
    # )

    time.sleep(3)

    archived_records = random.randint(1000, 10000)

    print(f"âœ… å½’æ¡£ {archived_records} æ¡è®°å½•")

    return {
        "table": table_name,
        "archived_records": archived_records,
        "cutoff_date": cutoff_date.strftime("%Y-%m-%d")
    }


# ============================================================
# ç³»ç»Ÿç»´æŠ¤ä»»åŠ¡
# ============================================================

@shared_task(name="tasks.cleanup_tasks.health_check")
def health_check():
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥

    å®šæ—¶ä»»åŠ¡:
        æ¯ 10 åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡

    æ£€æŸ¥é¡¹:
        - æ•°æ®åº“è¿æ¥
        - Redis è¿æ¥
        - ç£ç›˜ç©ºé—´
        - å†…å­˜ä½¿ç”¨ç‡
    """
    print(f"ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥...")

    health_status = {}

    # 1. æ£€æŸ¥æ•°æ®åº“
    print("   æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
    try:
        # from core.database import engine
        # async with engine.connect() as conn:
        #     await conn.execute("SELECT 1")
        health_status["database"] = "healthy"
    except Exception as e:
        health_status["database"] = "unhealthy"
        print(f"   âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

    time.sleep(0.5)

    # 2. æ£€æŸ¥ Redis
    print("   æ£€æŸ¥ Redis è¿æ¥...")
    try:
        # from core.redis import get_redis
        # redis = await get_redis()
        # await redis.ping()
        health_status["redis"] = "healthy"
    except Exception as e:
        health_status["redis"] = "unhealthy"
        print(f"   âŒ Redis è¿æ¥å¤±è´¥: {e}")

    time.sleep(0.5)

    # 3. æ£€æŸ¥ç£ç›˜ç©ºé—´
    print("   æ£€æŸ¥ç£ç›˜ç©ºé—´...")
    # import shutil
    # total, used, free = shutil.disk_usage("/")
    # disk_usage_percent = (used / total) * 100

    disk_usage_percent = random.uniform(30, 90)
    health_status["disk"] = {
        "usage_percent": round(disk_usage_percent, 2),
        "status": "healthy" if disk_usage_percent < 80 else "warning"
    }

    if disk_usage_percent > 80:
        print(f"   âš ï¸  ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: {disk_usage_percent:.2f}%")
        # å‘é€å‘Šè­¦
        from tasks.email_tasks import send_email
        send_email.delay(
            to="admin@example.com",
            subject="âš ï¸ ç£ç›˜ç©ºé—´å‘Šè­¦",
            body=f"ç£ç›˜ä½¿ç”¨ç‡: {disk_usage_percent:.2f}%"
        )

    time.sleep(0.5)

    # 4. æ£€æŸ¥å†…å­˜
    print("   æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡...")
    # import psutil
    # memory = psutil.virtual_memory()
    # memory_usage_percent = memory.percent

    memory_usage_percent = random.uniform(40, 90)
    health_status["memory"] = {
        "usage_percent": round(memory_usage_percent, 2),
        "status": "healthy" if memory_usage_percent < 85 else "warning"
    }

    if memory_usage_percent > 85:
        print(f"   âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage_percent:.2f}%")

    print(f"âœ… å¥åº·æ£€æŸ¥å®Œæˆ")

    # æ‰€æœ‰æ£€æŸ¥é€šè¿‡
    all_healthy = all(
        status == "healthy" or (isinstance(status, dict) and status["status"] == "healthy")
        for status in health_status.values()
    )

    return {
        "status": "healthy" if all_healthy else "warning",
        "checks": health_status,
        "timestamp": datetime.now().isoformat()
    }


@shared_task(name="tasks.cleanup_tasks.optimize_database")
def optimize_database():
    """
    ä¼˜åŒ–æ•°æ®åº“

    å®šæ—¶ä»»åŠ¡:
        æ¯å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ

    æ“ä½œ:
        - åˆ†æè¡¨
        - ä¼˜åŒ–è¡¨
        - é‡å»ºç´¢å¼•
        - æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"ğŸ”§ å¼€å§‹ä¼˜åŒ–æ•°æ®åº“...")

    tables = ["users", "posts", "comments", "orders"]

    for table in tables:
        print(f"   ä¼˜åŒ–è¡¨: {table}...")

        # å®é™…ä»£ç ï¼ˆMySQLï¼‰:
        # await db.execute(f"ANALYZE TABLE {table}")
        # await db.execute(f"OPTIMIZE TABLE {table}")

        # PostgreSQL:
        # await db.execute(f"VACUUM ANALYZE {table}")

        time.sleep(2)

    print(f"âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")

    return {"optimized_tables": tables}


@shared_task(name="tasks.cleanup_tasks.backup_database")
def backup_database():
    """
    å¤‡ä»½æ•°æ®åº“

    å®šæ—¶ä»»åŠ¡:
        æ¯å¤©å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ

    æ“ä½œ:
        1. å¯¼å‡ºæ•°æ®åº“
        2. å‹ç¼©å¤‡ä»½æ–‡ä»¶
        3. ä¸Šä¼ åˆ° OSS
        4. åˆ é™¤æœ¬åœ°å¤‡ä»½
        5. æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™ 7 å¤©ï¼‰
    """
    print(f"ğŸ’¾ å¼€å§‹å¤‡ä»½æ•°æ®åº“...")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = f"backup_{timestamp}.sql"

    # 1. å¯¼å‡ºæ•°æ®åº“
    print(f"   å¯¼å‡ºæ•°æ®åº“åˆ° {backup_file}...")
    # import subprocess
    # subprocess.run([
    #     'mysqldump',
    #     '-u', 'user',
    #     '-p', 'password',
    #     'database_name',
    #     '>', backup_file
    # ])

    time.sleep(5)

    # 2. å‹ç¼©
    print(f"   å‹ç¼©å¤‡ä»½æ–‡ä»¶...")
    # import gzip
    # with open(backup_file, 'rb') as f_in:
    #     with gzip.open(f'{backup_file}.gz', 'wb') as f_out:
    #         f_out.writelines(f_in)

    time.sleep(2)

    # 3. ä¸Šä¼ åˆ° OSS
    print(f"   ä¸Šä¼ åˆ° OSS...")
    # import oss2
    # bucket = oss2.Bucket(auth, endpoint, bucket_name)
    # bucket.put_object_from_file(f'backups/{backup_file}.gz', f'{backup_file}.gz')

    time.sleep(3)

    # 4. åˆ é™¤æœ¬åœ°æ–‡ä»¶
    print(f"   åˆ é™¤æœ¬åœ°æ–‡ä»¶...")
    # os.remove(backup_file)
    # os.remove(f'{backup_file}.gz')

    # 5. æ¸…ç†æ—§å¤‡ä»½
    print(f"   æ¸…ç† 7 å¤©å‰çš„å¤‡ä»½...")
    # ä» OSS åˆ é™¤æ—§å¤‡ä»½

    time.sleep(1)

    print(f"âœ… å¤‡ä»½å®Œæˆ")

    return {
        "backup_file": f"{backup_file}.gz",
        "timestamp": timestamp,
        "status": "success"
    }


# ============================================================
# å­¦ä¹ ç¬”è®°
# ============================================================
"""
å…³é”®æ¦‚å¿µæ€»ç»“ï¼š

1. ã€å®šæ—¶æ¸…ç†çš„é‡è¦æ€§ã€‘
   - èŠ‚çœå­˜å‚¨ç©ºé—´
   - æé«˜æŸ¥è¯¢æ€§èƒ½
   - æ•°æ®å®‰å…¨åˆè§„
   - ç³»ç»Ÿç¨³å®šè¿è¡Œ

2. ã€æ¸…ç†ç­–ç•¥ã€‘
   - è½¯åˆ é™¤ vs ç¡¬åˆ é™¤
   - å½’æ¡£ vs åˆ é™¤
   - ä¿ç•™æœŸé™è®¾ç½®
   - åˆ†æ‰¹åˆ é™¤ï¼ˆé¿å…é”è¡¨ï¼‰

3. ã€å¥åº·æ£€æŸ¥ã€‘
   - å®šæœŸæ£€æŸ¥ç³»ç»ŸçŠ¶æ€
   - è‡ªåŠ¨å‘Šè­¦
   - é¢„é˜²æ€§ç»´æŠ¤
   - é—®é¢˜æ—©å‘ç°

4. ã€æ•°æ®å¤‡ä»½ã€‘
   - æ¯æ—¥å¤‡ä»½
   - å¼‚åœ°å­˜å‚¨
   - å®šæœŸæ¢å¤æµ‹è¯•
   - ä¿ç•™å¤šä¸ªç‰ˆæœ¬

5. ã€æœ€ä½³å®è·µã€‘
   - éé«˜å³°æœŸæ‰§è¡Œï¼ˆå‡Œæ™¨ï¼‰
   - è®¾ç½®è¶…æ—¶æ—¶é—´
   - è®°å½•è¯¦ç»†æ—¥å¿—
   - å¤±è´¥å‘Šè­¦é€šçŸ¥

6. ã€å®é™…å·¥å…·ã€‘
   - psutil: ç³»ç»Ÿç›‘æ§
   - shutil: æ–‡ä»¶æ“ä½œ
   - subprocess: æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
   - schedule: å®šæ—¶ä»»åŠ¡è°ƒåº¦
"""
